{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0zm-v85WfkP",
        "outputId": "7baabbe3-9c9b-45c4-8113-7f3ad10cc83f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: KAGGLE_USERNAME=shivindass\n",
            "env: KAGGLE_KEY=6930b85bc2a7e49c2bf390121bee0341\n",
            "Downloading customers.csv.zip to /content\n",
            " 89% 87.0M/97.9M [00:00<00:00, 177MB/s]\n",
            "100% 97.9M/97.9M [00:00<00:00, 170MB/s]\n",
            "Downloading articles.csv.zip to /content\n",
            "  0% 0.00/4.26M [00:00<?, ?B/s]\n",
            "100% 4.26M/4.26M [00:00<00:00, 104MB/s]\n",
            "Downloading transactions_train.csv.zip to /content\n",
            "100% 583M/584M [00:06<00:00, 116MB/s] \n",
            "100% 584M/584M [00:06<00:00, 98.1MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "100% 50.3M/50.3M [00:00<00:00, 145MB/s]\n",
            "100% 50.3M/50.3M [00:00<00:00, 125MB/s]\n",
            "Archive:  customers.csv.zip\n",
            "replace dataset/customers.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: dataset/customers.csv   \n",
            "Archive:  articles.csv.zip\n",
            "replace dataset/articles.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "#download and unzip data\n",
        "%env KAGGLE_USERNAME=shivindass\n",
        "%env KAGGLE_KEY=6930b85bc2a7e49c2bf390121bee0341\n",
        "\n",
        "!kaggle competitions download -c h-and-m-personalized-fashion-recommendations -f customers.csv\n",
        "!kaggle competitions download -c h-and-m-personalized-fashion-recommendations -f articles.csv\n",
        "!kaggle competitions download -c h-and-m-personalized-fashion-recommendations -f transactions_train.csv\n",
        "!kaggle competitions download -c h-and-m-personalized-fashion-recommendations -f sample_submission.csv\n",
        "\n",
        "!unzip customers.csv.zip -d dataset\n",
        "!unzip articles.csv.zip -d dataset\n",
        "!unzip transactions_train.csv.zip -d dataset\n",
        "!unzip sample_submission.csv.zip -d dataset\n",
        "\n",
        "!rm customers.csv.zip articles.csv.zip transactions_train.csv.zip sample_submission.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXm1LkEZGeGE",
        "outputId": "36f2d0da-fb0c-42c0-b500-e59e7039ad3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting implicit\n",
            "  Downloading implicit-0.5.2-cp37-cp37m-manylinux2014_x86_64.whl (18.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.5 MB 464 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from implicit) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from implicit) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from implicit) (1.21.6)\n",
            "Installing collected packages: implicit\n",
            "Successfully installed implicit-0.5.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/implicit/gpu/__init__.py:14: UserWarning: CUDA extension is built, but disabling GPU support because of 'Cuda Error: no CUDA-capable device is detected (/project/./implicit/gpu/utils.h:71)'\n",
            "  f\"CUDA extension is built, but disabling GPU support because of '{e}'\",\n"
          ]
        }
      ],
      "source": [
        "#install implicit\n",
        "!pip install implicit\n",
        "\n",
        "import implicit\n",
        "from scipy.sparse import csr_matrix\n",
        "import pandas as pd\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1uFh6m-GL6-"
      },
      "outputs": [],
      "source": [
        "#utilities\n",
        "import os\n",
        "data_path = \"dataset/\"\n",
        "def load_csv(filename, dtype=str):\n",
        "  '''\n",
        "    load file from DATA_DIR/filename\n",
        "  '''\n",
        "  path = os.path.join(data_path, filename)\n",
        "\n",
        "  if os.path.exists(path):\n",
        "    return pd.read_csv(path, dtype=dtype)\n",
        "  else:\n",
        "    raise Exception(\n",
        "        \"Incorrect filepath: \" + path\n",
        "      )\n",
        "\n",
        "def save_csv(data, filename):\n",
        "  '''\n",
        "    save data to DAT_DIR/filename\n",
        "  '''\n",
        "  path = os.path.join(data_path, filename)\n",
        "  data.to_csv(path, index = False)\n",
        "\n",
        "\n",
        "def get_train_data(cutoff_date = '2020-09-15'):\n",
        "  '''\n",
        "    generate training data by only returning the transactions that took place on or before 2020-09-15\n",
        "  '''\n",
        "\n",
        "  train = load_csv(\"transactions_train.csv\")\n",
        "\n",
        "  train.t_dat = pd.to_datetime(train.t_dat)\n",
        "  if cutoff_date:\n",
        "    return train.loc[train.t_dat <= pd.to_datetime(cutoff_date)]\n",
        "  return train\n",
        "\n",
        "def get_val_data(cutoff_date = '2020-09-15'):\n",
        "  '''\n",
        "    generate validation data by only returning the articles purchased in the week 2020-09-16 to 2020-09-22  \n",
        "  '''\n",
        "\n",
        "  val = load_csv(\"transactions_train.csv\")\n",
        "  sub = load_csv(\"sample_submission.csv\")\n",
        "  cid = pd.Data\n",
        "\n",
        "  val.t_dat = pd.to_datetime(val.t_dat)\n",
        "  val = val.loc[val.t_dat > pd.to_datetime(cutoff_date)]\n",
        "\n",
        "  val = val.groupby('customer_id').article_id.apply(list).reset_index()\n",
        "  val = val.rename({'article_id' : 'prediction'}, axis = 1)\n",
        "  print(val.head)\n",
        "\n",
        "  val['prediction'] = val.prediction.apply(lambda x: ' '.join([str(k) for k in x]))\n",
        "  \n",
        "  val.rename(columns={\"Unnamed: 0\": \"customer_id\"})\n",
        "\n",
        "  for c in sample_sub['customer_id']:\n",
        "    print(val[c])\n",
        "  \n",
        "  return val\n",
        "\n",
        "'''\n",
        "    Code taken from kaggle's github repository - https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def apk(actual, predicted, k=12):\n",
        "    \"\"\"\n",
        "    Computes the average precision at k.\n",
        "    This function computes the average prescision at k between two lists of\n",
        "    items.\n",
        "    Parameters\n",
        "    ----------\n",
        "    actual : list\n",
        "             A list of elements that are to be predicted (order doesn't matter)\n",
        "    predicted : list\n",
        "                A list of predicted elements (order does matter)\n",
        "    k : int, optional\n",
        "        The maximum number of predicted elements\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "            The average precision at k over the input lists\n",
        "    \"\"\"\n",
        "    if len(predicted)>k:\n",
        "        predicted = predicted[:k]\n",
        "\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "\n",
        "    for i,p in enumerate(predicted):\n",
        "        if p in actual and p not in predicted[:i]:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i+1.0)\n",
        "\n",
        "    if not actual:\n",
        "        return 0.0\n",
        "\n",
        "    return score / min(len(actual), k)\n",
        "\n",
        "def mapk(actual, predicted, k=12):\n",
        "    \"\"\"\n",
        "    Computes the mean average precision at k.\n",
        "    This function computes the mean average prescision at k between two lists\n",
        "    of lists of items.\n",
        "    Parameters\n",
        "    ----------\n",
        "    actual : list\n",
        "             A list of lists of elements that are to be predicted \n",
        "             (order doesn't matter in the lists)\n",
        "    predicted : list\n",
        "                A list of lists of predicted elements\n",
        "                (order matters in the lists)\n",
        "    k : int, optional\n",
        "        The maximum number of predicted elements\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "            The mean average precision at k over the input lists\n",
        "    \"\"\"\n",
        "    return np.mean([apk(a.split(),p.split(),k) for a,p in zip(actual, predicted)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ9m3taHIyox",
        "outputId": "4cad79df-4545-4f61-8155-3529a502ffa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of                                              customer_id  \\\n",
            "0      00039306476aaf41a07fed942884f16b30abfa83a2a8be...   \n",
            "1      0003e867a930d0d6842f923d6ba7c9b77aba33fe2a0fbf...   \n",
            "2      000493dd9fc463df1acc2081450c9e75ef8e87d5dd17ed...   \n",
            "3      000525e3fe01600d717da8423643a8303390a055c578ed...   \n",
            "4      00077dbd5c4a4991e092e63893ccf29294a9d5c46e8501...   \n",
            "...                                                  ...   \n",
            "68979  fffa67737587e52ff1afa9c7c6490b5eb7acbc439fe82b...   \n",
            "68980  fffa7d7799eb390a76308454cbdd76e473d65b1497fbe4...   \n",
            "68981  fffae8eb3a282d8c43c77dd2ca0621703b71e90904dfde...   \n",
            "68982  fffd870c6324ad3bda24e4d6aeae221c199479086bfdfd...   \n",
            "68983  fffef3b6b73545df065b521e19f64bf6fe93bfd450ab20...   \n",
            "\n",
            "                                              prediction  \n",
            "0                                           [0624486001]  \n",
            "1                                           [0827487003]  \n",
            "2                   [0757926001, 0788575004, 0640021019]  \n",
            "3                                           [0874110016]  \n",
            "4      [0903762001, 0879189005, 0158340001, 086796600...  \n",
            "...                                                  ...  \n",
            "68979                           [0874816003, 0911870004]  \n",
            "68980                           [0861803014, 0849886010]  \n",
            "68981  [0396135007, 0817472007, 0715624050, 081747200...  \n",
            "68982                           [0750423010, 0761269001]  \n",
            "68983                                       [0898573003]  \n",
            "\n",
            "[68984 rows x 2 columns]>\n"
          ]
        }
      ],
      "source": [
        "val = get_val_data(cutoff_date='2020-09-15')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_03vpLuKzNQ"
      },
      "outputs": [],
      "source": [
        "#Load train and val data\n",
        "cutoff_date = '2020-09-15'\n",
        "transactions = get_train_data(cutoff_date = cutoff_date)\n",
        "val = get_val_data(cutoff_date = cutoff_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e_l0Cf5SfI6",
        "outputId": "93a3a98e-51dc-46ac-d1c8-57488fe83346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        t_dat                                        customer_id  article_id  \\\n",
            "84 2018-09-20  00609a1cc562140fa87a6de432bef9c9f0b936b259ad30...  0611415005   \n",
            "85 2018-09-20  00609a1cc562140fa87a6de432bef9c9f0b936b259ad30...  0578374001   \n",
            "86 2018-09-20  00609a1cc562140fa87a6de432bef9c9f0b936b259ad30...  0673677002   \n",
            "87 2018-09-20  00609a1cc562140fa87a6de432bef9c9f0b936b259ad30...  0676352001   \n",
            "88 2018-09-20  00609a1cc562140fa87a6de432bef9c9f0b936b259ad30...  0611415001   \n",
            "\n",
            "                   price sales_channel_id  \n",
            "84  0.016932203389830508                2  \n",
            "85  0.042355932203389825                2  \n",
            "86  0.016932203389830508                2  \n",
            "87  0.025406779661016947                2  \n",
            "88  0.016932203389830508                2  \n"
          ]
        }
      ],
      "source": [
        "article_n = 20000\n",
        "customer_n = 20000\n",
        "\n",
        "customer_counts = transactions['customer_id'].value_counts()\n",
        "article_counts = transactions['article_id'].value_counts()\n",
        "\n",
        "sub_sample = transactions[transactions['article_id'].isin(article_counts.index[:article_n]) & transactions['customer_id'].isin(customer_counts.index[:customer_n])]\n",
        "\n",
        "article_to_index = {article_counts.index[i]: i for i in range(article_n)}\n",
        "customer_to_index = {customer_counts.index[i]: i for i in range(customer_n)}\n",
        "\n",
        "#create sparse matrix\n",
        "art_per_cust = sub_sample[['article_id', 'customer_id']].value_counts()\n",
        "max_art_per_cust = art_per_cust[0]\n",
        "\n",
        "data = list(art_per_cust[:])/max_art_per_cust\n",
        "\n",
        "row_ind = []\n",
        "col_ind = []\n",
        "for a, c in art_per_cust.index:\n",
        "  row_ind.append(customer_to_index[c])\n",
        "  col_ind.append(article_to_index[a])\n",
        "\n",
        "user_item_matrix = csr_matrix((data, (row_ind, col_ind)), shape=(customer_n, article_n))\n",
        "\n",
        "#train model\n",
        "model = implicit.als.AlternatingLeastSquares(iterations=30, factors=128)\n",
        "model.fit(user_item_matrix)\n",
        "\n",
        "#make predictions\n",
        "submission = load_csv(\"sample_submission.csv\")\n",
        "\n",
        "most_popular_pred = ' '.join(article_counts.index[:12])\n",
        "predictions = []\n",
        "for cust_id in tqdm.tqdm(submission[\"customer_id\"]):\n",
        "  if cust_id in customer_to_index.keys():\n",
        "    cust_index = customer_to_index[cust_id]\n",
        "    recommendations = model.recommend(userid = cust_index, user_items = user_item_matrix[cust_index], N=12, filter_already_liked_items=False)\n",
        "    predicted_items = []\n",
        "    for r in recommendations[0]:\n",
        "      predicted_items.append(article_counts.index[r])\n",
        "    predictions.append(' '.join(predicted_items))\n",
        "  else:\n",
        "    predictions.append(most_popular_pred)\n",
        "# print(predictions)\n",
        "submission['prediction'] = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnRKNqURHQEV"
      },
      "outputs": [],
      "source": [
        "mapk(val['prediction'], submission['prediction'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPLnUI06D2CH",
        "outputId": "bebab5d1-5a8a-48ca-ceea-883c6ca1002f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 258M/258M [00:12<00:00, 21.7MB/s]\n",
            "Successfully submitted to H&M Personalized Fashion Recommendations"
          ]
        }
      ],
      "source": [
        "# save_csv(submission, \"submission.csv\")\n",
        "# !kaggle competitions submit -c h-and-m-personalized-fashion-recommendations -f dataset/submission.csv -m \"Matrix fact\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "csci567_matrix_factorization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}